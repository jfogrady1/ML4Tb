{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay,roc_curve,auc, make_scorer,mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.decomposition import PCA, NMF, FastICA\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#font for plots\n",
    "font = {'fontname':'Arial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "# Note the raw will be for if individuals wish to put in a MAD filter on the data\n",
    "train_data = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/vst_individual/human_train_vst_normalised_data.txt\", sep = \"\\t\").T\n",
    "test_data = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/vst_individual/human_test_vst_normalised_data.txt\", sep = \"\\t\").T\n",
    "val_data = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/vst_individual/human_val_vst_normalised_data.txt\", sep = \"\\t\").T\n",
    "train_labels = pd.read_csv(\"/home/workspace/jogrady/ML4TB/data/human/train_labels.txt\", sep = \"\\t\").T.to_numpy() \n",
    "test_labels = pd.read_csv(\"/home/workspace/jogrady/ML4TB/data/human/test_labels.txt\", sep = \"\\t\").T.to_numpy() \n",
    "val_labels = pd.read_csv(\"/home/workspace/jogrady/ML4TB/data/human/val_labels.txt\", sep = \"\\t\").T.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the normalised data for pairwise comparison\n",
    "train_data_test_normalised = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/vst_combined/human_train_vst_normalised_human_test.txt\", sep = \"\\t\").T\n",
    "train_data_val_normalised = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/vst_combined/human_train_vst_normalised_human_val.txt\", sep = \"\\t\").T\n",
    "test_data_train_normalised = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/vst_combined/human_test_vst_normalised_human_train.txt\", sep = \"\\t\").T\n",
    "test_data_val_normalised = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/vst_combined/human_test_vst_normalised_human_val.txt\", sep = \"\\t\").T\n",
    "val_data_train_normalised = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/vst_combined/human_val_vst_normalised_human_train.txt\", sep = \"\\t\").T\n",
    "val_data_test_normalised = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/vst_combined/human_val_vst_normalised_human_test.txt\", sep = \"\\t\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.loc[:,~train_data.columns.duplicated()].copy()\n",
    "test_data = test_data.loc[:,~test_data.columns.duplicated()].copy()\n",
    "val_data = val_data.loc[:,~val_data.columns.duplicated()].copy()\n",
    "# And for pairwise comparison\n",
    "train_data_test_normalised = train_data_test_normalised.loc[:,~train_data_test_normalised.columns.duplicated()].copy()\n",
    "train_data_val_normalised = train_data_val_normalised.loc[:,~train_data_val_normalised.columns.duplicated()].copy()\n",
    "test_data_train_normalised = test_data_train_normalised.loc[:,~test_data_train_normalised.columns.duplicated()].copy()\n",
    "test_data_val_normalised = test_data_val_normalised.loc[:,~test_data_val_normalised.columns.duplicated()].copy()\n",
    "val_data_train_normalised = val_data_train_normalised.loc[:,~val_data_train_normalised.columns.duplicated()].copy()\n",
    "val_data_test_normalised = val_data_test_normalised.loc[:,~val_data_test_normalised.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training Set\n",
    "## Gene based\n",
    "\n",
    "We need to Train the models on the trianing set, evlauate via k fold cross validation internally. THen we need to do the same in the test and val and then do a cross comparison on eachother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte variances for VST normalised genes\n",
    "variances = train_data.var(axis=0)\n",
    "variances = variances\n",
    "# take top 20% and filter\n",
    "threshold = variances.quantile(.80) \n",
    "genes = variances > threshold\n",
    "genes= genes.loc[genes==True].index\n",
    "train_data = train_data.filter(items = genes, axis=1)\n",
    "\n",
    "# Reapply to test\n",
    "#test_data = test_data.filter(items = genes, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 11092) (61, 55460) (60, 55460)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape, val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "KF =  KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a pipeline for logistic regression and set the paramaters\n",
    "log_pipe = Pipeline(steps=[\n",
    "('scaler', StandardScaler()), # see comment above (in markdown)\n",
    "('classifier', LogisticRegression(max_iter=10000, solver='saga', tol=0.0001, random_state=42))]) # classifier\n",
    "\n",
    "precision_scorer = make_scorer(precision_score, zero_division=1)  # had to modify zero_division as it was giving problems\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "\n",
    "# Define scoring dictionary for GridSearchCV\n",
    "scoring = {\n",
    "    'accuracy': accuracy_scorer,\n",
    "    'f1': f1_scorer,\n",
    "    'precision': precision_scorer,\n",
    "    'recall': recall_scorer\n",
    "}\n",
    "\n",
    "# Create a parameter grid - we will search through all these combinations\n",
    "param_grid = {\n",
    "    'classifier__penalty': [\"elasticnet\"],\n",
    "    'classifier__l1_ratio': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "}\n",
    " \n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(log_pipe, param_grid, cv=KF, verbose=1, n_jobs=60, scoring=scoring, refit=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000,\n",
       "                                                           random_state=42,\n",
       "                                                           solver=&#x27;saga&#x27;))]),\n",
       "             n_jobs=60,\n",
       "             param_grid={&#x27;classifier__l1_ratio&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6,\n",
       "                                                  0.7, 0.8, 0.9],\n",
       "                         &#x27;classifier__penalty&#x27;: [&#x27;elasticnet&#x27;]},\n",
       "             refit=&#x27;accuracy&#x27;,\n",
       "             scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score),\n",
       "                      &#x27;f1&#x27;: make_scorer(f1_score),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score, zero_division=1),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score)},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000,\n",
       "                                                           random_state=42,\n",
       "                                                           solver=&#x27;saga&#x27;))]),\n",
       "             n_jobs=60,\n",
       "             param_grid={&#x27;classifier__l1_ratio&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6,\n",
       "                                                  0.7, 0.8, 0.9],\n",
       "                         &#x27;classifier__penalty&#x27;: [&#x27;elasticnet&#x27;]},\n",
       "             refit=&#x27;accuracy&#x27;,\n",
       "             scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score),\n",
       "                      &#x27;f1&#x27;: make_scorer(f1_score),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score, zero_division=1),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score)},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(max_iter=10000, random_state=42,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, random_state=42, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(max_iter=10000,\n",
       "                                                           random_state=42,\n",
       "                                                           solver='saga'))]),\n",
       "             n_jobs=60,\n",
       "             param_grid={'classifier__l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6,\n",
       "                                                  0.7, 0.8, 0.9],\n",
       "                         'classifier__penalty': ['elasticnet']},\n",
       "             refit='accuracy',\n",
       "             scoring={'accuracy': make_scorer(accuracy_score),\n",
       "                      'f1': make_scorer(f1_score),\n",
       "                      'precision': make_scorer(precision_score, zero_division=1),\n",
       "                      'recall': make_scorer(recall_score)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_data, train_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing: Count non-zero coefficients\n",
    "# unfortunatley, grid search CV doesn't return coefficients for all models so we will have to re run and fit with all the paramaters again\n",
    "non_zero_counts = []\n",
    "for params, mean_score in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_accuracy']):\n",
    "    # Manually fit the pipeline with the parameters\n",
    "    model = log_pipe.set_params(**params)\n",
    "    model.fit(train_data, train_labels.ravel())  # Re-fit the model on the entire dataset\n",
    "    non_zero_count = np.sum(model.named_steps['classifier'].coef_ != 0)\n",
    "    non_zero_counts.append((params, mean_score, non_zero_count))\n",
    "\n",
    "non_zero_counts_df = pd.DataFrame(non_zero_counts)\n",
    "\n",
    "non_zero_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
