{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying logistic regression in python to discriminate between control and M. bovis infected animals using peripheral blood transcriptomics data\n",
    "### This analysis considers two approaches, one using logistic regression on variable genes that have been preprocessed using DESeq2 (vst normalised) and the other using latent variables inferred using PCA, ICA and NMF\n",
    "\n",
    "\n",
    "RNA-seq data often suffers from a curse of dimensionality whereby there are many more features/genes (p) than samples (n) and this can lead to model overfitting, spurious correlations and poor generalizability. Hence, there are strategies to mitigate against this issue.\n",
    "Such strategies include: applying a penalization to input features to account for multi-collinearity. Other strategies involve projecting the data into a reduced dimensional space and using these latent variabels (e.g. PCs) as input for a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay,roc_curve,auc, make_scorer,mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.decomposition import PCA, NMF, FastICA\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#font for plots\n",
    "font = {'fontname':'Arial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "# Note the raw will be for if individuals wish to put in a MAD filter on the data\n",
    "train_data_raw = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/Train_raw_data.txt\", sep = \"\\t\").T\n",
    "test_data_raw = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/Test_raw_data.txt\", sep = \"\\t\").T\n",
    "train_data = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/Train_vst_normalised_data.txt\", sep = \"\\t\").T\n",
    "test_data = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/Test_vst_normalised_data.txt\", sep = \"\\t\").T\n",
    "train_labels = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/Train_labels.txt\", sep = \"\\t\").T \n",
    "test_labels = pd.read_csv(\"/home/workspace/jogrady/ML4TB/work/normalisation/Test_labels.txt\", sep = \"\\t\").T.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do some data wrangling to ensure labels are in right format for ML functions in scikit learn\n",
    "# Convert labels to numeric really is the main thing\n",
    "train_labels = train_labels.to_numpy()\n",
    "train_labels = np.where(train_labels == \"Control\", 0, np.where(train_labels == \"Infected\", 1, train_labels))\n",
    "test_labels = np.where(test_labels == \"Control\", 0, np.where(test_labels == \"Infected\", 1, test_labels))\n",
    "train_labels = train_labels.astype(int)\n",
    "test_labels = test_labels.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was unsure as to whether or not VST normalsied gene expression data should be scaled further (e.g. using StandardScaler) as this could increase technical noise (which would is initially removed in the VST step). However, Dr Mike love (author of DESeq2) clears it up with comments below in the context of glmnet (R package)\n",
    "\n",
    "- \"Scaling (for each gene, across samples) and VST are to some degree at odds. The VST shrinks technical variance so that biological differences are not overwhelmed. And doing so it outperforms simply transformations such as log(x + 1). But then if you force all genes to have unit variance, you undo that effect, increasing technical noise which was just shrunk.\n",
    "\n",
    " - I'd suggest you use the VST, then use a variance filter on the VST data to remove genes with minimal variance (take a look at the meanSdPlot to get a sense of the genes which likely have no biological signal, see vignette), then feed the remaining genes to glmnet with standardize=TRUE\". - https://support.bioconductor.org/p/93160/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte variances for VST normalised genes\n",
    "variances = train_data.var(axis=0)\n",
    "# take top 20% and filter\n",
    "threshold = variances.quantile(.80) \n",
    "genes = variances > threshold\n",
    "genes= genes.loc[genes==True].index\n",
    "train_data = train_data.filter(items = genes, axis=1)\n",
    "\n",
    "# Reapply to test\n",
    "test_data = test_data.filter(items = genes, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5522 most variable genes (note this is still more than we had DE)\n",
    "test_data.shape\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up k fold cross validation and set random_state to 42 to ensure reproducibility - THis ensures each fold in evaluation is the same\n",
    "KF =  KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a pipeline for logistic regression and set the paramaters\n",
    "log_pipe = Pipeline(steps=[\n",
    "('scaler', StandardScaler()), # see comment above (in markdown)\n",
    "('classifier', LogisticRegression(max_iter=10000, solver='saga', tol=0.0001, random_state=42))]) # classifier\n",
    "\n",
    "precision_scorer = make_scorer(precision_score, zero_division=1)  # had to modify zero_division as it was giving problems\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "\n",
    "# Define scoring dictionary for GridSearchCV\n",
    "scoring = {\n",
    "    'accuracy': accuracy_scorer,\n",
    "    'f1': f1_scorer,\n",
    "    'precision': precision_scorer,\n",
    "    'recall': recall_scorer\n",
    "}\n",
    "\n",
    "# Create a parameter grid - we will search through all these combinations\n",
    "param_grid = {\n",
    "    'classifier__penalty': [\"elasticnet\"],\n",
    "    'classifier__l1_ratio': [0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1]\n",
    "}\n",
    " \n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(log_pipe, param_grid, cv=KF, verbose=1, n_jobs=60, scoring=scoring, refit=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search\n",
    "grid_search.fit(train_data, train_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at best paramaters and accuracy and save results to a data frame\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Best CV average accuracy: {grid_search.best_score_:.2f}\")\n",
    "results_genes = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),\n",
    "           pd.DataFrame(grid_search.cv_results_[\"mean_test_accuracy\"], columns = [\"Average Accuracy\"]),\n",
    "           pd.DataFrame(grid_search.cv_results_[\"std_test_accuracy\"], columns=[\"SD accuracy\"]),\n",
    "           pd.DataFrame(grid_search.cv_results_[\"mean_test_precision\"], columns = [\"Average precision\"]),\n",
    "           pd.DataFrame(grid_search.cv_results_[\"std_test_precision\"], columns=[\"SD precision\"]),\n",
    "           pd.DataFrame(grid_search.cv_results_[\"mean_test_recall\"], columns=[\"Average recall\"]),\n",
    "           pd.DataFrame(grid_search.cv_results_[\"std_test_recall\"], columns=[\"SD recall\"])],axis=1)\n",
    "results_genes.sort_values(by='Average Accuracy', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.named_steps[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_genes\n",
    "results_models = pd.DataFrame(grid_search.cv_results_)\n",
    "results_models.sort_values(by='rank_test_accuracy', inplace=True)\n",
    "results_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_full_lasso = results_models.iloc[7]['params']\n",
    "print(params_full_lasso)\n",
    "clf_2nd_best_full_lasso = grid_search.best_estimator_.set_params(**params_full_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in case we ever need it again e.g. for external data\n",
    "with open('/home/workspace/jogrady/ML4TB/work/models/Logistic_regression_CV_search.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.DataFrame(zip(train_data.columns, np.transpose(grid_search.best_estimator_.named_steps[\"classifier\"].coef_)), columns=['features', 'coef'])#.sort_values(by='coef', inplace=True)\n",
    "data_test.sort_values(by='coef', inplace = True)\n",
    "data_test = data_test.loc[(data_test != 0).all(axis=1), :]\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(clf_2nd_best_full_lasso.predict(test_data), test_labels.ravel()) # Note decision threshold is 0.5 meaning there are some difficult to classify samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Control', 'Infected']\n",
    "print(classification_report(test_labels.ravel(), grid_search.predict(test_data), target_names=target_names))\n",
    "Gene_cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(test_labels.ravel(),grid_search.predict(test_data)), display_labels = [\"Control\", \"Infected\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using latent variables as a means of reducing dimensionality and extracting biological insight\n",
    "\n",
    "### 2.1 PCA\n",
    "\n",
    "People generally choose the elbow method for picking the optimal number of PCs. However, others choose the numbr of PCs that explain e.g 80, 90 95% of the variation as input. Unclear which is best so we will settle for 80% as an upper limit and evaluate the contribution of differening number of PCs before picking the best model to evaluate on the test set\n",
    "\n",
    "- Side point: The number of PCs is important to specify for ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Do not need to scale for PCA - not recommended in VST\n",
    "pca = PCA(random_state=88, n_components=87)\n",
    "pca.fit(train_data)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "# Plotting the elbow curve\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(range(1, 87 + 1), explained_variance, marker='o')\n",
    "plt.xlabel('Number of Principal Components based on training set')\n",
    "plt.ylabel('Variance explained')\n",
    "plt.title('Elbow Method for Optimal Number of Components in training set')\n",
    "plt.grid()\n",
    "plt.xticks(range(1, 87 + 1,2))\n",
    "plt.axvline(x=11, color='r', linestyle='--', label='Optimal Components (based on elbow)')\n",
    "plt.axvline(x=36, color='g', linestyle='--', label='80% variance captured')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(f'Variance captured by 36 PCs:{pca.explained_variance_ratio_[:36].sum():.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Set up the PCA logistic regression pipeline and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the pipeline\n",
    "PCA_Pipeline = Pipeline(steps=[('pca', PCA(random_state=42)),\n",
    "('classifier', LogisticRegression(max_iter=10000, penalty=\"none\", solver='saga', tol=0.0001, random_state=42))])\n",
    "\n",
    "# Set up a grid for each PC\n",
    "pca_param_grid = {'pca__n_components': list(range(1, 37))}\n",
    "\n",
    "# Apply\n",
    "LR_pca_search_model = GridSearchCV(PCA_Pipeline, pca_param_grid, cv=KF, scoring=scoring, refit=\"accuracy\")\n",
    "\n",
    "# Fit\n",
    "LR_pca_search_model.fit(train_data, train_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at best paramaters and accuracy and save results to a data frame\n",
    "print(f\"Best Paramater:\", LR_pca_search_model.best_params_)\n",
    "print(f\"Best Score: {LR_pca_search_model.best_score_:.2f}\")\n",
    "results_pca = pd.concat([pd.DataFrame(LR_pca_search_model.cv_results_[\"params\"]),\n",
    "           pd.DataFrame(LR_pca_search_model.cv_results_[\"mean_test_accuracy\"], columns = [\"CV Accuracy\"]),\n",
    "           pd.DataFrame(LR_pca_search_model.cv_results_[\"std_test_accuracy\"], columns=[\"SD accuracy\"]),\n",
    "           pd.DataFrame(LR_pca_search_model.cv_results_[\"mean_test_precision\"], columns = [\"CV precision\"]),\n",
    "           pd.DataFrame(LR_pca_search_model.cv_results_[\"std_test_precision\"], columns=[\"SD precision\"]),\n",
    "           pd.DataFrame(LR_pca_search_model.cv_results_[\"mean_test_recall\"], columns=[\"CV recall\"]),\n",
    "           pd.DataFrame(LR_pca_search_model.cv_results_[\"std_test_recall\"], columns=[\"SD recall\"])],axis=1)\n",
    "results_pca.sort_values(by='CV Accuracy', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Plot each of the components and find the genes that are driving each of them and also, find components that are different between the two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'residuals_all.columns' contains the names of the genes\n",
    "\n",
    "pca = PCA(random_state=42, n_components=30)\n",
    "pca_fit = pca.fit(train_data)\n",
    "comp_genes= []\n",
    "pca_genes = pd.DataFrame()\n",
    "pca_results = pca_fit.fit_transform(train_data)\n",
    "colors = ['steelblue' if label == 0 else 'crimson' for label in train_labels.ravel()]\n",
    "plt.scatter(pca_results[:, 0], pca_results[:, 1], label=\"Training data\", c=colors, s=20)\n",
    "handles = [plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='steelblue', markersize=5, label='Control'),\n",
    "           plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='crimson', markersize=5, label='Infected')]\n",
    "plt.title(\"PCA Visualization of eigenvectors\", fontweight='bold')\n",
    "plt.legend(handles=handles)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "# Iterate through each component\n",
    "for component_idx in range(30):\n",
    "    # Calculate loadings for the current component\n",
    "    loadings = pca_fit.components_.T * np.sqrt(pca_fit.explained_variance_)\n",
    "\n",
    "    # Sort genes by their influence on the current component\n",
    "    sorted_genes = train_data.columns[np.argsort(loadings[:, component_idx])]\n",
    "\n",
    "    # Visualize the top N genes that contribute the most to the current component\n",
    "    N = pca_fit.components_.shape[1]\n",
    "    top_genes = sorted_genes[-N:]\n",
    "\n",
    "    pca_genes[component_idx] = top_genes[::-1]\n",
    "    comp_genes = np.append(comp_genes, top_genes)\n",
    "pca_genes.columns = [\"Component_1\",\"Component_2\",\"Component_3\",\"Component_4\",\n",
    "                     \"Component_5\",\"Component_6\",\"Component_7\",\"Component_8\",\n",
    "                     \"Component_9\",\"Component_10\",\"Component_11\",\"Component_12\",\n",
    "                     \"Component_13\",\"Component_14\",\"Component_15\",\"Component_16\",\n",
    "                     \"Component_17\",\"Component_18\",\"Component_19\",\"Component_20\",\n",
    "                     \"Component_21\",\"Component_22\",\"Component_23\",\"Component_24\",\n",
    "                     \"Component_25\",\"Component_26\",\"Component_27\",\"Component_28\",\n",
    "                     \"Component_29\",\"Component_30\"]                      \n",
    "pca_genes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the grid for subplots (10 rows, 3 columns)\n",
    "fig, axes = plt.subplots(10, 3, figsize=(18, 30))\n",
    "fig.suptitle(\"PCA Visualization of Eigenvectors\", fontweight='bold', fontsize=16)\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop to generate scatter plots from PC1 vs each PC up to PC30\n",
    "for i in range(1, 30):\n",
    "    ax = axes[i-1]\n",
    "    ax.scatter(pca_results[:, 0], pca_results[:, i], c=colors, s=20)\n",
    "    ax.set_title(f\"PC1 vs PC{i+1}\")\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(f\"PC{i+1}\")\n",
    "\n",
    "# Custom legend only in the first subplot (for cleanliness)\n",
    "handles = [\n",
    "    plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='steelblue', markersize=5, label='Control'),\n",
    "    plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='crimson', markersize=5, label='Infected')\n",
    "]\n",
    "axes[0].legend(handles=handles)\n",
    "\n",
    "# Hide any unused subplots (since there are only 29 plots for a 30-slot grid)\n",
    "for j in range(29, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_weight_pca = pd.DataFrame(zip(pca_genes.columns, np.transpose(LR_pca_search_model.best_estimator_.named_steps[\"classifier\"].coef_)), columns=['features', 'coef'])#.sort_values(by='coef', inplace=True)\n",
    "Feature_weight_pca.sort_values(by='coef', inplace = True)\n",
    "Feature_weight_pca = Feature_weight_pca.loc[(Feature_weight_pca != 0).all(axis=1), :]\n",
    "Feature_weight_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(pca_results)\n",
    "Control = df_pca.iloc[:44, :] # 45 samples in control\n",
    "Infected = df_pca.iloc[45:, :] # 42 in infected\n",
    "\n",
    "# Perform t-test for each component\n",
    "results = pd.DataFrame(columns=['Component', 'T-Statistic', 'P-Value'])\n",
    "\n",
    "for column in df_pca.columns:\n",
    "    t_statistic, p_value = stats.ttest_ind(Control[column], Infected[column])\n",
    "    \n",
    "    new_row = pd.DataFrame({'Component': [column], 'T-Statistic': [t_statistic], 'P-Value': [p_value]})\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "# Print the results\n",
    "print(results)\n",
    "\n",
    "# Identify components with significantly different means\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "reject, pvals_corrected, _, _ = multipletests(results[\"P-Value\"], alpha=0.05, method='fdr_bh')\n",
    "results['Corrected P-Value'] = pvals_corrected\n",
    "results['Significant (BH)'] = reject \n",
    "\n",
    "\n",
    "significantly_different = results[results['Corrected P-Value'] < 0.05]\n",
    "print(\"Components with significantly different means:\")\n",
    "print(significantly_different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for each component\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(results['Component'], -np.log10(results['Corrected P-Value']), color='teal', alpha=0.5)\n",
    "\n",
    "plt.xlabel('PCA Component Number', fontsize=18)\n",
    "plt.ylabel('-log10(P-Value)', fontsize=18)\n",
    "plt.plot([-1,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],np.repeat(-np.log10(0.05),32),linestyle='--', label='Padj=0.05')\n",
    "plt.title('PCA: Difference per Component between Control and Infected samples', \n",
    "            fontsize=20, fontweight='bold')\n",
    "plt.xticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30], fontsize=16)\n",
    "plt.ylim(0,4)\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlim(-0.5,29.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see there is a significnat difference in the components for PC1, 5 and 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Evaluate on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on Test data\n",
    "print(classification_report(test_labels.ravel(), LR_pca_search_model.predict(test_data), target_names=target_names))\n",
    "PCA_cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(test_labels.ravel(),LR_pca_search_model.predict(test_data)), display_labels = [\"Control\", \"Infected\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ICA\n",
    "\n",
    "ICA and PCA are similar to each other however ICA attemps to transform the data into statistically significant non-Gaussian components. Often times this is estimated by Kurtosis but the number of  !'PCs'! used for the whitening procedure is often those that reach 80,90,95% etc, hence we will use this for below  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICA\n",
    "from sklearn.decomposition import FastICA\n",
    "ICA_transformer = FastICA(n_components=36, # from PCA - 80% of variance\n",
    "        random_state=42,\n",
    "        max_iter=1000, tol=0.0001,\n",
    "        whiten='unit-variance')\n",
    "\n",
    "df_train_ica = ICA_transformer.fit_transform(train_data)\n",
    "kurtosis_scores = [kurtosis(df_train_ica[:, i]) for i in range(df_train_ica.shape[1])]\n",
    "n_components = np.argmax(kurtosis_scores) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of non-normal components in training data = 14 - however we will use the same as above for PCA\n",
    "n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that 14 components are non-gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the pipeline\n",
    "ICA_Pipeline = Pipeline(steps=[('ica', FastICA( \n",
    "        random_state=42,\n",
    "        max_iter=5000, tol=0.0001,\n",
    "        whiten='unit-variance')),\n",
    "('classifier', LogisticRegression(max_iter=10000, penalty=\"none\", solver='saga', tol=0.0001, random_state=42))])\n",
    "\n",
    "# Set up grid of components - 80% from PCA above\n",
    "ica_param_grid = {'ica__n_components': list(range(1, 37))}\n",
    "\n",
    "\n",
    "# Apply\n",
    "LR_ica_search_model = GridSearchCV(ICA_Pipeline, ica_param_grid, cv=KF, scoring=scoring, refit=\"accuracy\")\n",
    "\n",
    "\n",
    "# Fit\n",
    "LR_ica_search_model.fit(train_data, train_labels.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at best paramaters and accuracy and save results to a data frame\n",
    "print(\"Best Parameters:\", LR_ica_search_model.best_params_)\n",
    "print(f\"Best Score: {LR_ica_search_model.best_score_:.2f}\")\n",
    "results_ica = pd.concat([pd.DataFrame(LR_pca_search_model.cv_results_[\"params\"]),\n",
    "           pd.DataFrame(LR_ica_search_model.cv_results_[\"mean_test_accuracy\"], columns = [\"CV Accuracy\"]),\n",
    "           pd.DataFrame(LR_ica_search_model.cv_results_[\"std_test_accuracy\"], columns=[\"SD accuracy\"]),\n",
    "           pd.DataFrame(LR_ica_search_model.cv_results_[\"mean_test_precision\"], columns = [\"CV precision\"]),\n",
    "           pd.DataFrame(LR_ica_search_model.cv_results_[\"std_test_precision\"], columns=[\"SD precision\"]),\n",
    "           pd.DataFrame(LR_ica_search_model.cv_results_[\"mean_test_recall\"], columns=[\"CV recall\"]),\n",
    "           pd.DataFrame(LR_ica_search_model.cv_results_[\"std_test_recall\"], columns=[\"SD recall\"])],axis=1)\n",
    "results_ica.sort_values(by='CV Accuracy', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels.ravel(),LR_ica_search_model.predict(test_data), target_names=target_names))\n",
    "ICA_cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(test_labels.ravel(),LR_ica_search_model.predict(test_data)), display_labels = [\"Control\", \"Infected\"])\n",
    "# display matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NMF_Pipeline = Pipeline(steps=[('nmf', NMF(\n",
    "    init=\"random\", solver='cd', \n",
    "    beta_loss='frobenius', tol=0.0001, \n",
    "    max_iter=10000, random_state=42, verbose=0)),\n",
    "('classifier', LogisticRegression(max_iter=10000, penalty=None, solver='saga', tol=0.0001, random_state=42))])\n",
    "\n",
    "nmf_param_grid = {'nmf__n_components': list(range(1, 37))}\n",
    "\n",
    "LR_nmf_search_model = GridSearchCV(NMF_Pipeline, nmf_param_grid, cv=KF, n_jobs= 30, scoring=scoring, refit=\"accuracy\")\n",
    "\n",
    "LR_nmf_search_model.fit(train_data, train_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at best paramaters and accuracy and save results to a data frame\n",
    "print(\"Best Parameters:\", LR_nmf_search_model.best_params_)\n",
    "print(f\"Best Score: {LR_nmf_search_model.best_score_:.2f}\")\n",
    "results_nmf = pd.concat([pd.DataFrame(LR_pca_search_model.cv_results_[\"params\"]),\n",
    "           pd.DataFrame(LR_nmf_search_model.cv_results_[\"mean_test_accuracy\"], columns = [\"CV Accuracy\"]),\n",
    "           pd.DataFrame(LR_nmf_search_model.cv_results_[\"std_test_accuracy\"], columns=[\"SD accuracy\"]),\n",
    "           pd.DataFrame(LR_nmf_search_model.cv_results_[\"mean_test_precision\"], columns = [\"CV precision\"]),\n",
    "           pd.DataFrame(LR_nmf_search_model.cv_results_[\"std_test_precision\"], columns=[\"SD precision\"]),\n",
    "           pd.DataFrame(LR_nmf_search_model.cv_results_[\"mean_test_recall\"], columns=[\"CV recall\"]),\n",
    "           pd.DataFrame(LR_nmf_search_model.cv_results_[\"std_test_recall\"], columns=[\"SD recall\"])],axis=1)\n",
    "results_nmf.sort_values(by='CV Accuracy', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels.ravel(), LR_nmf_search_model.predict(test_data), target_names=target_names))\n",
    "NMF_cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(test_labels.ravel(),LR_nmf_search_model.predict(test_data)), display_labels = [\"Control\", \"Infected\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### 1. Confusion matrix\n",
    " - Note, this is based on a theta value of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genes\n",
    "Gene_cm_display.plot()\n",
    "plt.title(\"Performance of best gene-based model on test data\")\n",
    "\n",
    "# PCA\n",
    "PCA_cm_display.plot()\n",
    "plt.title('PCA best model on test data')\n",
    "\n",
    "# ICA\n",
    "ICA_cm_display.plot()\n",
    "plt.title('ICA best model on test data')\n",
    "\n",
    "# NMF\n",
    "NMF_cm_display.plot()\n",
    "plt.title('NMF best model on test data')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict continuous value\n",
    "# For different decision thresholds\n",
    "y_score_gene = grid_search.predict_proba(test_data)\n",
    "fprG_gene, tprG_gene, t_gene = roc_curve(test_labels.ravel(), y_score_gene[:,1])\n",
    "roc_aucG_gene = auc(fprG_gene, tprG_gene)\n",
    "\n",
    "\n",
    "y_score_pca = LR_pca_search_model.predict_proba(test_data)\n",
    "fprG_pca, tprG_pca, t_pca = roc_curve(test_labels.ravel(), y_score_pca[:,1])\n",
    "roc_aucG_pca = auc(fprG_pca, tprG_pca)\n",
    "\n",
    "\n",
    "y_score_ica = LR_pca_search_model.predict_proba(test_data)\n",
    "fprG_ica, tprG_ica, t_ica = roc_curve(test_labels.ravel(), y_score_ica[:,1])\n",
    "roc_aucG_ica = auc(fprG_ica, tprG_ica)\n",
    "\n",
    "\n",
    "\n",
    "y_score_nmf = LR_pca_search_model.predict_proba(test_data)\n",
    "fprG_nmf, tprG_nmf, t_nmf = roc_curve(test_labels.ravel(), y_score_nmf[:,1])\n",
    "roc_aucG_nmf = auc(fprG_nmf, tprG_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fprG_gene, tprG_gene, color='red',\n",
    "         lw=lw, label='ROC Gene (area = %0.2f)' % roc_aucG_gene)\n",
    "plt.plot(fprG_pca, tprG_pca, color='green',\n",
    "         lw=lw, label='ROC PCA (area = %0.2f)' % roc_aucG_pca)\n",
    "plt.plot(fprG_ica, tprG_ica, color='red',\n",
    "         lw=lw, label='ROC ICA (area = %0.2f)' % roc_aucG_ica)\n",
    "plt.plot(fprG_nmf, tprG_nmf, color='blue',\n",
    "         lw=lw, label='ROC NMF (area = %0.2f)' % roc_aucG_nmf)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Analysis Different models')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Bite NMF covers both PCA and ICA as they are identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Look at coefficients of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.named_steps['classifier'].coef_\n",
    "coefficient_data_frame = pd.DataFrame({\"GeneID\": np.array(train_data.columns),\n",
    "                                       \"Coefficient\": grid_search.best_estimator_.named_steps['classifier'].coef_.ravel()})\n",
    "coefficient_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write results to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_genes.to_csv(path_or_buf = \"/home/workspace/jogrady/ML4TB/work/LogisticRegression/Gene_based_CV_search.txt\", sep = \"\\t\", index = False)\n",
    "results_pca.to_csv(path_or_buf = \"/home/workspace/jogrady/ML4TB/work/LogisticRegression/PCA_CV_search.txt\", sep = \"\\t\", index = False)\n",
    "results_ica.to_csv(path_or_buf = \"/home/workspace/jogrady/ML4TB/work/LogisticRegression/ICA_based_CV_search.txt\", sep = \"\\t\", index = False)\n",
    "results_nmf.to_csv(path_or_buf = \"/home/workspace/jogrady/ML4TB/work/LogisticRegression/NMF_based_CV_search.txt\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
